# Caches

Cache is a memory that holds a subset of main memory.

Ideal cache would predict with 100% accuracy what data processor will need. 
__hit__ - 


## Temporal and spacial locality
- temporal (related to time). Processor is likely to access the data again soon.
- spatial. Processor is likely to access the adjacent regions of data.


## Direct mapped cache
- Contains sets that are 1 block in size.

## How is main memory mapped to cache?

Address is divided into 3 sections.
[Tag][Set][Byte offset]

- set: decides to which set the data goes
- offset: not taken into account in direct mapped cache
- tag: identifies unique address


## N way associative caches
An N-way set associative cache reduces conflicts by providing N blocks in each set


## Fully associative cache:

[Tag][Set][Block offset][Byte offset]
B-ways. Fewest misses, but the most complex structure.
Can fit an entire block, therefore benefits from spatial locality.

## Who goes out?
LRU _(Least Recently Used)_ policy


## Cache misses reasons
1. Capacity misses. They occur when cache is simply too small to hold all concurently used data.

2. Conflict misses. They occur when several addresses map to the same set.

3. Compulsory misses. Occur during the first request to cache a block. They are not avoidable.


## Write policies
1. _Write-through_ caches
During write, the block is written to both cache and main memory

2. _Write-back_ cache
The memory is written to main memory only after it is evicted from cache. They are usually the ones used in real-world caches.


